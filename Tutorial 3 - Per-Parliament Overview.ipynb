{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef52dea",
   "metadata": {},
   "source": [
    "### Tutorial 3 - Per-Parliament Overview (PDF)\n",
    "\n",
    "In this tutorial, we create one PDF overview per parliament, including:\n",
    "- Mean sentiment scores per CAP_category\n",
    "- Distribution of total speeches\n",
    "- Avg. + median speech length \n",
    "- Word count x topic distribution\n",
    "- Gini-coefficient of word counts across topics\n",
    "- Spearman correlation scatterplot of topic share x mean sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970dc23",
   "metadata": {},
   "source": [
    "**1. Setup**\n",
    "\n",
    "First, we have to set up the requirements: install and load all necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe5a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import datetime\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56442dc4",
   "metadata": {},
   "source": [
    "**2. Data Loading & Filtering**\n",
    "\n",
    "Now, we **read and filter** the data. This code:\n",
    "- loads the selected columns of the datasets and merges them into a single DataFrame.\n",
    "- selects only those that were held by Regular MPs (*Members of Parliament*) and filters out the CAP categories \"Mix\" and \"Other\". \n",
    "- creates separate DataFrames for coalition and opposition party speeches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1009473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All filtered: (4565042, 21)\n"
     ]
    }
   ],
   "source": [
    "# ---- 1. First, we have to increase the CSV field size limit ----\n",
    "max_int = 2**31 - 1\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(max_int)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        max_int = max_int // 10\n",
    "\n",
    "countries = [\"AT\", \"BA\", \"BE\", \"BG\", \"CZ\", \"DK\", \"EE\", \"ES-CT\", \"ES-GA\", \"ES-PV\", \n",
    "             \"FR\", \"GB\", \"GR\", \"HR\", \"HU\", \"IS\", \"IT\", \"LV\", \n",
    "             \"NL\", \"NO\", \"PL\", \"PT\", \"RS\", \"SE\", \"SI\", \"TR\", \"UA\"] #change country codes according to your available datasets\n",
    "\n",
    "base_dir = Path().resolve()\n",
    "\n",
    "# ---- 2. Choose what columns to read (including CAP and sentiment columns) ----\n",
    "cols_to_keep = [\n",
    "    \"id\", \"date\", \"lang_code\", \"lang\", \"speaker_role\", \"speaker_MP\",\n",
    "    \"speaker_minister\", \"speaker_party\", \"speaker_party_name\", \"party_status\",\n",
    "    \"party_orientation\", \"speaker_id\", \"speaker_name\", \"speaker_gender\",\n",
    "    \"speaker_birth\", \"word_count\", \"CAP_category\", \"sent3_category\", \"sent6_category\", \"sent_logit\"\n",
    "]\n",
    "\n",
    "# ---- 3. Define dtypes to reduce memory ----\n",
    "dtypes = {\n",
    "    \"id\": str,\n",
    "    \"date\": str,\n",
    "    \"lang_code\": \"category\",\n",
    "    \"lang\": \"category\",\n",
    "    \"speaker_role\": \"category\",\n",
    "    \"speaker_MP\": \"category\",\n",
    "    \"speaker_minister\": \"category\",\n",
    "    \"speaker_party\": \"category\",\n",
    "    \"speaker_party_name\": \"category\",\n",
    "    \"party_status\": \"category\",\n",
    "    \"party_orientation\": \"category\",\n",
    "    \"speaker_id\": \"category\",\n",
    "    \"speaker_name\": \"category\",\n",
    "    \"speaker_gender\": \"category\",\n",
    "    \"speaker_birth\": \"Int32\",\n",
    "    \"word_count\": \"Int32\",\n",
    "    \"CAP_category\": \"category\",\n",
    "    \"sent3_category\": \"category\",\n",
    "    \"sent6_category\": \"category\",\n",
    "    \"sent_logit\": \"float32\"\n",
    "}\n",
    "\n",
    "# ---- 4. Create lists to accumulate filtered chunks ----\n",
    "all_chunks = []\n",
    "\n",
    "for country in countries:\n",
    "    file_path = base_dir / f\"ParlaMint-{country}_processed_no_text.tsv\"\n",
    "\n",
    "    # --- 4.1. Read in chunks using pandas.read_csv ----\n",
    "    for chunk in pd.read_csv(file_path, sep=\"\\t\", usecols=cols_to_keep,\n",
    "                             dtype=dtypes, chunksize=50_000, engine=\"python\"):\n",
    "        chunk[\"country\"] = country\n",
    "        chunk[\"country\"] = chunk[\"country\"].astype(\"category\")\n",
    "\n",
    "        # ---- 4.2. Filter MPs with regular role ----\n",
    "        filtered_chunk = chunk.query(\"speaker_MP == 'MP' and speaker_role == 'Regular'\")\n",
    "\n",
    "        # ---- 4.3. Drop rows where CAP_category or sentiment is empty ----\n",
    "        filtered_chunk = filtered_chunk[\n",
    "            filtered_chunk[\"CAP_category\"].notna() & (filtered_chunk[\"CAP_category\"] != \"\") &\n",
    "            filtered_chunk[\"sent3_category\"].notna() & (filtered_chunk[\"sent3_category\"] != \"\") &\n",
    "            filtered_chunk[\"sent6_category\"].notna() & (filtered_chunk[\"sent6_category\"] != \"\")\n",
    "        ]\n",
    "\n",
    "        # ---- 4.4. Accumulate filtered chunks ----\n",
    "        if not filtered_chunk.empty:\n",
    "            all_chunks.append(filtered_chunk)\n",
    "\n",
    "# ---- 5. Concatenate all accumulated chunks into DataFrames ----\n",
    "filtered_all = pd.concat(all_chunks, ignore_index=True)\n",
    "del all_chunks\n",
    "print(\"All filtered:\", filtered_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8618926",
   "metadata": {},
   "source": [
    "**Filter out** the CAP categories **\"Mix\" and \"Other\"** (because these labels aren't informative enough for the following analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac699dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_all = filtered_all[~filtered_all[\"CAP_category\"].isin([\"Mix\", \"Other\"])]\n",
    "filtered_all[\"CAP_category\"] = filtered_all[\"CAP_category\"].cat.remove_unused_categories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e602d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for one country of your choice\n",
    "country = \"AT\"\n",
    "country_data = filtered_all[filtered_all[\"country\"] == country].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdbbd90",
   "metadata": {},
   "source": [
    "**3. PDF creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "368a852c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isabe\\AppData\\Local\\Temp\\ipykernel_22144\\3561684443.py:105: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n",
      "C:\\Users\\isabe\\AppData\\Local\\Temp\\ipykernel_22144\\3561684443.py:112: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha=\"right\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF saved as AT_speech_analysis.pdf\n"
     ]
    }
   ],
   "source": [
    "# ---- 1. Speech stats per CAP category (avg. + median speech length, total number of speeches + words & mean sentiment) ----\n",
    "speech_stats = (\n",
    "    country_data\n",
    "    .groupby(\"CAP_category\", observed=True)\n",
    "    .agg(\n",
    "        avg_speech_len=(\"word_count\", \"mean\"),      # avg. words per speech\n",
    "        median_speech_len=(\"word_count\", \"median\"), # median words per speech\n",
    "        total_speeches=(\"word_count\", \"count\"),     # number of speeches\n",
    "        total_words=(\"word_count\", \"sum\"),          # total words spoken in that topic\n",
    "        mean_sent=(\"sent_logit\", \"mean\")            # average sentiment\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ---- 1.1. Round numeric summary columns ----\n",
    "speech_stats[\"avg_speech_len\"] = speech_stats[\"avg_speech_len\"].round(2)\n",
    "speech_stats[\"median_speech_len\"] = speech_stats[\"median_speech_len\"].round(2)\n",
    "speech_stats[\"mean_sent\"] = speech_stats[\"mean_sent\"].round(2)\n",
    "\n",
    "# ---- 2. Aggreate total words and mean sentiment per CAP category ----\n",
    "agg = (\n",
    "    country_data\n",
    "    .groupby(\"CAP_category\", observed=True)\n",
    "    .agg(mean_sent=(\"sent_logit\", \"mean\"), total_words=(\"word_count\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ---- 2.1. Compute topic share (percentage of total words per topic) ----\n",
    "if agg[\"total_words\"].sum() > 0:\n",
    "    agg[\"topic_share_pct\"] = (agg[\"total_words\"] / agg[\"total_words\"].sum()) * 100\n",
    "else:\n",
    "    agg[\"topic_share_pct\"] = 0.0\n",
    "\n",
    "# ---- 2.2. Compute Spearman correlation (topic share vs. mean sentiment) ----\n",
    "if len(agg) > 1:\n",
    "    corr_coef, p_value = spearmanr(agg[\"topic_share_pct\"], agg[\"mean_sent\"])\n",
    "else:\n",
    "    corr_coef, p_value = (float(\"nan\"), float(\"nan\"))\n",
    "\n",
    "# ---- 3. Total-level summary for cover page ----\n",
    "total_speeches = int(country_data.shape[0])\n",
    "total_words = int(country_data[\"word_count\"].sum())\n",
    "avg_sent = float(country_data[\"sent_logit\"].mean()) if total_speeches > 0 else float(\"nan\")\n",
    "median_sent = float(country_data[\"sent_logit\"].median()) if total_speeches > 0 else float(\"nan\")\n",
    "avg_len = float(country_data[\"word_count\"].mean()) if total_speeches > 0 else float(\"nan\")\n",
    "median_len = float(country_data[\"word_count\"].median()) if total_speeches > 0 else float(\"nan\")\n",
    "\n",
    "# ---- 5. Top 3 topics by total words (for the cover page) ----\n",
    "top3 = agg.sort_values(\"total_words\", ascending=False).head(3)\n",
    "top3_lines = [\n",
    "    f\"{row['CAP_category']}: {int(row['total_words']):,} words ({row['topic_share_pct']:.1f}%)\"\n",
    "    for _, row in top3.iterrows()\n",
    "]\n",
    "\n",
    "# ---- Helper for formatting integers ----\n",
    "def fmt_num(n):\n",
    "    try:\n",
    "        return f\"{int(n):,}\"\n",
    "    except Exception:\n",
    "        return str(n)\n",
    "\n",
    "date_str = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ----- Build cover page figure -----\n",
    "fig_cover = plt.figure(figsize=(8.27, 11.69))  # A4 portrait\n",
    "fig_cover.patch.set_facecolor(\"white\")\n",
    "ax = fig_cover.add_subplot(111)\n",
    "ax.axis(\"off\")\n",
    "\n",
    "title = f\"ParlaMint Country Analysis — {country}\"\n",
    "subtitle = f\"Generated: {date_str}\"\n",
    "\n",
    "left_x = 0.06\n",
    "y = 0.88\n",
    "ax.text(left_x, y, title, fontsize=20, weight=\"bold\", transform=fig_cover.transFigure)\n",
    "ax.text(left_x, y - 0.04, subtitle, fontsize=10, color=\"gray\", transform=fig_cover.transFigure)\n",
    "\n",
    "# ---- Stats block ----\n",
    "y0 = y - 0.12\n",
    "line_height = 0.045\n",
    "ax.text(left_x, y0, f\"Total speeches: {fmt_num(total_speeches)}\", fontsize=12, transform=fig_cover.transFigure)\n",
    "ax.text(left_x, y0 - line_height, f\"Total words: {fmt_num(total_words)}\", fontsize=12, transform=fig_cover.transFigure)\n",
    "ax.text(left_x, y0 - 2*line_height, f\"Avg sentiment (sent_logit): {avg_sent:.2f}\", fontsize=12, transform=fig_cover.transFigure)\n",
    "ax.text(left_x, y0 - 3*line_height, f\"Median sentiment: {median_sent:.2f}\", fontsize=12, transform=fig_cover.transFigure)\n",
    "ax.text(left_x, y0 - 4*line_height, f\"Avg speech length (words): {avg_len:.1f}\", fontsize=12, transform=fig_cover.transFigure)\n",
    "ax.text(left_x, y0 - 5*line_height, f\"Median speech length: {median_len:.1f}\", fontsize=12, transform=fig_cover.transFigure)\n",
    "\n",
    "# ---- Top topics printed on the cover ----\n",
    "ax.text(left_x, y0 - 7*line_height, \"Top topics (by words):\", fontsize=12, weight=\"bold\", transform=fig_cover.transFigure)\n",
    "for i, line in enumerate(top3_lines):\n",
    "    ax.text(left_x + 0.02, y0 - (8+i)*line_height, f\"{i+1}. {line}\", fontsize=11, transform=fig_cover.transFigure)\n",
    "\n",
    "# ---- Small footer note ----\n",
    "ax.text(0.06, 0.05, \"Note: topic shares are based on total words spoken in each topic.\", fontsize=8, color=\"gray\", transform=fig_cover.transFigure)\n",
    "\n",
    "# ----- 6. Create PDF and append pages (cover + plots + table) -----\n",
    "pdf_path = f\"{country}_speech_analysis.pdf\"\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    # ---- 6.1. Cover page ----\n",
    "    pdf.savefig(fig_cover)\n",
    "    plt.close(fig_cover)\n",
    "\n",
    "    # ---- 6.2. Barplot: total words per CAP category ----\n",
    "    fig1, ax1 = plt.subplots(figsize=(12,6))\n",
    "    sns.barplot(\n",
    "        data=agg.sort_values(\"total_words\", ascending=False),\n",
    "        x=\"CAP_category\",\n",
    "        y=\"total_words\",\n",
    "        palette=\"viridis\",\n",
    "        ax=ax1\n",
    "    )\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    ax1.set_ylabel(\"Total Word Count\")\n",
    "    ax1.set_xlabel(\"CAP Category\")\n",
    "    ax1.set_title(f\"Total Word Counts Across Topics in {country}\")\n",
    "    fig1.tight_layout()\n",
    "    pdf.savefig(fig1)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # ---- 6.3. Scatter: topic share vs mean sentiment ----\n",
    "    fig2, ax2 = plt.subplots(figsize=(8,5))\n",
    "\n",
    "    num_topics = len(agg[\"CAP_category\"].unique())\n",
    "    palette = sns.color_palette(\"hsv\", num_topics)  # dynamic palette\n",
    "\n",
    "    sns.scatterplot(\n",
    "        data=agg,\n",
    "        x=\"topic_share_pct\",\n",
    "        y=\"mean_sent\",\n",
    "        hue=\"CAP_category\",\n",
    "        palette=palette,\n",
    "        s=100,\n",
    "        ax=ax2\n",
    "    )\n",
    "    if not np.isnan(corr_coef):\n",
    "        sns.regplot(data=agg, x=\"topic_share_pct\", y=\"mean_sent\", scatter=False, ci=None, color=\"gray\", ax=ax2)\n",
    "\n",
    "    ax2.set_title(f\"{country} — Topic Share vs. Mean Sentiment\")\n",
    "    ax2.set_xlabel(\"Topic Share (%)\")\n",
    "    ax2.set_ylabel(\"Mean Sentiment (sent_logit)\")\n",
    "\n",
    "    # ---- Place legend outside the plot ----\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    if handles:\n",
    "        ax2.legend(handles, labels, title=\"Topic\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    fig2.tight_layout()\n",
    "    pdf.savefig(fig2)\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # ---- 7. Table: speech_stats (create display-friendly copy) ----\n",
    "    table_display = speech_stats.copy()\n",
    "    table_display[\"total_speeches\"] = table_display[\"total_speeches\"].apply(lambda x: f\"{int(x):,}\")\n",
    "    table_display[\"total_words\"] = table_display[\"total_words\"].apply(lambda x: f\"{int(x):,}\")\n",
    "    table_display = table_display[[\"CAP_category\", \"avg_speech_len\", \"median_speech_len\", \"total_speeches\", \"total_words\", \"mean_sent\"]]\n",
    "\n",
    "    fig3, ax3 = plt.subplots(figsize=(12, max(6, 0.25*len(table_display))))\n",
    "    ax3.axis(\"off\")\n",
    "    tbl = ax3.table(cellText=table_display.values, colLabels=table_display.columns, loc='center', cellLoc='center')\n",
    "    tbl.auto_set_font_size(False)\n",
    "    tbl.set_fontsize(9)\n",
    "    tbl.scale(1, 1.2)\n",
    "    ax3.set_title(f\"{country} — Speech Statistics by CAP Category\")\n",
    "    fig3.tight_layout()\n",
    "    pdf.savefig(fig3)\n",
    "    plt.close(fig3)\n",
    "\n",
    "print(f\"PDF saved as {pdf_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praksa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
